{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RNN으로 이름 분류하기, https://tutorials.pytorch.kr/intermediate/char_rnn_classification_tutorial\n",
    "단어 분류를 위한 문자-단위 RNN implementation & training\n",
    "NLP 모델링을 위한 데이터 전처리를 위한 라이브러리(torchtext)를 사용하지 않고\n",
    "학습을 위해 데이터 전처리 과정 from scratch\n",
    "주어진 이름이 어떤 언어로 이루어 졌는지 예측하기 위해,\n",
    "18개 언어로 된 수천 개의 이름을 학습\n",
    "\n",
    "download data : https://download.pytorch.org/tutorial/data.zip\n",
    "\n",
    "Good explanation post for understanding RNN and LSTM, Korean\n",
    "https://dgkim5360.tistory.com/entry/understanding-long-short-term-memory-lstm-kr\n",
    "\"\"\"\n",
    "# Data preparation, from scratch\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "\n",
    "# check the name of all files for training\n",
    "print(findFiles('data/names/*.txt'))\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "# all ASCII code char & count the number of them\n",
    "all_letters = string.ascii_letters + \" .,;\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "print(all_letters)\n",
    "\n",
    "\n",
    "# 유니코드 문자열을 ASCII로 변환, https://stackoverflow.com/a/518232/2809427\n",
    "# unicode data normalize method : NFC, NFD, NFKD, NFKC\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != '\\n'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "\n",
    "# check Unicode to ASCII code\n",
    "print(unicodeToAscii('Ślusàrski'))\n",
    "\n",
    "# create 언어 종류 list & 언어별 학습 data\n",
    "all_categories = []\n",
    "category_lines = {}\n",
    "\n",
    "\n",
    "# read file & split line by line >> return split file line list\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "\n",
    "# read training data\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "# check category type & contents(names)\n",
    "print(all_categories)\n",
    "print(category_lines['Italian'][:5])\n",
    "\n",
    "'''\n",
    "Name to Tensor : One-Hot vector\n",
    "character - <1 * n_letters>\n",
    "word - combine each char, <line_length * 1 * n_letters>\n",
    "1 dim on the middle show batch 1, PyTorch assumes that everything is in batch\n",
    "'''\n",
    "import torch\n",
    "\n",
    "\n",
    "# find the address of a character with all_letters, 'a': 0 / 'b': 1 / ...\n",
    "def letterToiIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "\n",
    "# For verification, change one char to tensor\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToiIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "# one name(== one line) to One-Hot tensor array <line_length * 1 * n_letters>\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToiIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "print(letterToTensor('J'))\n",
    "print(lineToTensor('Jones').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create Network\n",
    "'''\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)\n",
    "\n",
    "# Example : running one step\n",
    "input = letterToTensor('A')\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input, hidden)\n",
    "\n",
    "# Example plus : For efficiency, make all tensors and cut them before to use\n",
    "input = lineToTensor('Albert')\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnprac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dfae11ec3b3824217917d19d1c1fbbb6c4c16fa871e0fbc5a61961091516534f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
